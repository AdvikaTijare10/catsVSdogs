# ğŸ§  Reflections & Learnings from My First CNN Project

This was my **first ever CNN project**, and I absolutely enjoyed building it!  
It was both challenging and exciting to see how a machine learning model could distinguish between images of cats and dogs. I used TensorFlow and Keras in Google Colab, and explored many important deep learning concepts hands-on for the first time.

Here are some of the most valuable things I learned during this journey:

---

## ğŸ” 1. Overfitting & Regularization

At first, I thought that **increasing the number of layers and filters** would improve my model. It did â€” *but only on the training set*. My validation accuracy didnâ€™t improve much, and validation loss started increasing, indicating **overfitting**.

To reduce overfitting, I learned and applied:
- **Dropout**: Randomly turns off neurons during training to prevent dependency on specific features.
- **EarlyStopping**: Automatically stops training when the model stops improving on the validation set.
- **Data Augmentation**: Introduced more variation in training data (like flips, rotations, zoom), which helped generalize the model better.

---

## ğŸ“Š 2. Validation vs Training Accuracy and Loss

- **Training Accuracy/Loss** tells how well the model fits the training data.
- **Validation Accuracy/Loss** shows how well the model performs on **unseen** data during training.

ğŸ” I observed that:
- When validation accuracy is much lower than training accuracy, it usually means the model is **overfitting**.
- When both are low, the model is likely **underfitting** (not learning enough).
- When validation loss starts increasing but training loss decreases, it's a warning sign of overfitting.

---

## âš–ï¸ 3. Overfitting vs Underfitting

**Overfitting** happens when the model memorizes the training data and doesnâ€™t generalize well.  
**Underfitting** means the model is too simple or hasnâ€™t learned enough from the data.

| Overfitting | Underfitting |
|-------------|--------------|
| High train accuracy, low val accuracy | Low train and val accuracy |
| Model is too complex | Model is too simple |
| Fix: Regularization, more data | Fix: More layers, better training |

Understanding this balance was key to building a reliable model.

---

## ğŸ”„ 4. What Happens in One Epoch?

One **epoch** is when the model has seen **all the training data once**.

In one epoch:
- Data is split into **batches**
- The model:
  - Makes predictions on each batch
  - Calculates loss
  - Updates weights using backpropagation
- After all batches are processed, it's considered **one epoch complete**

Usually, training takes multiple epochs for the model to gradually improve.

---

## ğŸ§ª 5. Validation Set vs Test Set

| Validation Set | Test Set |
|----------------|----------|
| Used during training | Used only after training is complete |
| Helps tune model & hyperparameters | Evaluates final model performance |
| Seen by the model (indirectly) | **Never seen** by the model before |

ğŸ”‘ I used a **validation split** during training (20% of data) and evaluated final accuracy using a **separate test set**.

---

## â¤ï¸ Final Thoughts

This project really helped me understand the core ideas of deep learning â€” not just by reading, but by *seeing* the impact of different techniques in action. From watching the model learn to identifying overfitting, it was a super rewarding experience.

Iâ€™m excited to take on more CNN projects next â€” maybe even go into satellite or telescope image classification next! ğŸ“¡ğŸ›°ï¸

---
